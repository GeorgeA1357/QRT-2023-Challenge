{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "a033e1d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LinearRegression, BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from bayes_opt import BayesianOptimization\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "b88ecb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_matrix=pd.DataFrame(index=[\"SR\",\"MSE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f635a87",
   "metadata": {},
   "source": [
    "## Reading data in/define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "26e2450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw=pd.read_csv(\"X_train.csv\")\n",
    "y_train_raw=pd.read_csv(\"y_train.csv\")\n",
    "X_test_raw=pd.read_csv(\"X_test.csv\")\n",
    "\n",
    "X_train_raw=X_train_raw.drop([\"DE_FR_EXCHANGE\",\"DE_NET_IMPORT\",\"FR_NET_IMPORT\"],axis=1)\n",
    "\n",
    "\n",
    "#lets drop the redundant stuff\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_train_raw,y_train_raw,test_size=0.2,random_state=13)\n",
    "\n",
    "y_train=y_train[\"TARGET\"]\n",
    "y_test=y_test[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "b860d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_country(df,y_df,country: str):\n",
    "    \n",
    "    y_df=y_df[df[\"COUNTRY\"]==country]\n",
    "    df=df[df[\"COUNTRY\"]==country]\n",
    "    df=df.drop([\"ID\",\"DAY_ID\",\"COUNTRY\"],axis=1)\n",
    "    df.fillna(df.median(),inplace=True)\n",
    "    \n",
    "    return df,y_df\n",
    "\n",
    "def ridgeregression(df,y_df):\n",
    "    \n",
    "    lrcv=RidgeCV(store_cv_values=True)\n",
    "    lrcv.fit(df,y_df)\n",
    "    #lr=Ridge(alpha=lrcv.alpha_)\n",
    "    lr=Ridge(alpha=10)\n",
    "    lr.fit(df,y_df)\n",
    "    \n",
    "    return lr\n",
    "\n",
    "def SVRegression(df,y_df,C=10,epsilon=0.01):\n",
    "    \n",
    "    model=SVR(kernel=\"linear\",C=C,epsilon=epsilon)\n",
    "    model.fit(df,y_df[\"TARGET\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def SVRegressionP(df,y_df,degree,C=10,epsilon=0.01):\n",
    "    \n",
    "    model=SVR(kernel=\"poly\",degree=degree,C=C,epsilon=epsilon)\n",
    "    model.fit(df,y_df[\"TARGET\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def SVR_error_de(C,epsilon):\n",
    "    \n",
    "    df=de_scale\n",
    "    y_df=y_de_scale\n",
    "    model=SVR(kernel=\"linear\",C=C,epsilon=epsilon)\n",
    "    model.fit(df,y_df[\"TARGET\"])\n",
    "    y_pred=model.predict(df)\n",
    "    mse=mean_squared_error(y_df[\"TARGET\"],y_pred)\n",
    "    \n",
    "    return -mse\n",
    "\n",
    "def SVR_error_fr(C,epsilon):\n",
    "    \n",
    "    df=fr_scale\n",
    "    y_df=y_fr_scale\n",
    "    model=SVR(kernel=\"linear\",C=C,epsilon=epsilon)\n",
    "    model.fit(df,y_df[\"TARGET\"])\n",
    "    y_pred=model.predict(df)\n",
    "    mse=mean_squared_error(y_df[\"TARGET\"],y_pred)\n",
    "    \n",
    "    return -mse\n",
    "     \n",
    "def postprocess(df_fr,df_de,x,y):\n",
    "    \n",
    "    fr=0\n",
    "    de=0\n",
    "    out=[]\n",
    "\n",
    "    for i in range (y.shape[0]):\n",
    "        if x['COUNTRY'].values[i]=='FR':\n",
    "            out.append([df_fr[fr]])\n",
    "            fr = fr + 1\n",
    "        else:\n",
    "            out.append([df_de[de]])\n",
    "            de = de + 1\n",
    "\n",
    "    return np.array(out)\n",
    "\n",
    "def z_scale(data):\n",
    "    \n",
    "    data=pd.DataFrame(data)\n",
    "    scaler=StandardScaler()\n",
    "    normalized_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "def lasso(df,y_df):\n",
    "    #lasso_cv=LassoCV(cv=10,max_iter=10000)\n",
    "    #lasso_cv.fit(df,y_df)\n",
    "    lasso=Lasso(alpha=0.05)\n",
    "    lasso.fit(df,y_df)\n",
    "    relevant_vars=df.columns[lasso.coef_!=0]\n",
    "\n",
    "    return list(relevant_vars)\n",
    "\n",
    "def Gboost(df,y_df):\n",
    "    gbr=GradientBoostingRegressor(n_estimators=100,learning_rate=0.1,max_depth=3)\n",
    "    gbr.fit(df,y_df[\"TARGET\"])\n",
    "    \n",
    "    return gbr\n",
    "\n",
    "def spearman(output, y):\n",
    "\n",
    "    return spearmanr(output, y).correlation\n",
    "\n",
    "def spear_loss(y_true,y_pred):\n",
    "    rho=tf.py_function(lambda yt, yp: spearmanr(yt, yp).correlation, [y_true,y_pred], [tf.float32])\n",
    "    return -rho[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c7ee12",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "b12d2a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set: 29.0%\n"
     ]
    }
   ],
   "source": [
    "lr=LinearRegression()\n",
    "\n",
    "X_train_clean = X_train.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "Y_train_clean = y_train\n",
    "\n",
    "lr.fit(X_train_clean, Y_train_clean)\n",
    "output_train = lr.predict(X_train_clean)\n",
    "\n",
    "print('Spearman correlation for the train set: {:.1f}%'.format(100 * spearman(output_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "9db01f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set: 21.6%\n",
      "MSE: 0.806\n"
     ]
    }
   ],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = lr.predict(X_test_clean)\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "\n",
    "print('Spearman correlation for the train set: {:.1f}%'.format(100 * spearman(lr.predict(X_test_clean),y_test)))\n",
    "print(\"MSE: {:.3f}\".format(mse_test))\n",
    "\n",
    "results_matrix[\"Benchmark\"]=[100*spearman(lr.predict(X_test_clean),y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d0e996",
   "metadata": {},
   "source": [
    "## Split the dataset into countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "fc28df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set\n",
    "de_train,y_de_train=split_into_country(X_train,y_train,\"DE\")\n",
    "fr_train,y_fr_train=split_into_country(X_train,y_train,\"FR\")\n",
    "\n",
    "#test set\n",
    "de_test,y_de_test=split_into_country(X_test,y_test,\"DE\")\n",
    "fr_test,y_fr_test=split_into_country(X_test,y_test,\"FR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90eac62",
   "metadata": {},
   "source": [
    "## Ridge regression testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "eddf19ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set using RidgeRegression divided into countries: 37.0%\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "de_train_ridge=ridgeregression(de_train,y_de_train)\n",
    "fr_train_ridge=ridgeregression(fr_train,y_fr_train)\n",
    "\n",
    "#make predictions on test set\n",
    "fr_train_pred=fr_train_ridge.predict(fr_train)\n",
    "de_train_pred=de_train_ridge.predict(de_train)\n",
    "\n",
    "train_out=postprocess(fr_train_pred,de_train_pred,X_train,y_train)\n",
    "\n",
    "print('Spearman correlation for the train set using RidgeRegression divided into countries: {:.1f}%'.format(100 *spearman(train_out, y_train) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "d83701fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set using RidgeRegression divided into countries: 25.1%\n"
     ]
    }
   ],
   "source": [
    "#use the model to predict form the test set\n",
    "fr_test_pred=fr_train_ridge.predict(fr_test)\n",
    "de_test_pred=de_train_ridge.predict(de_test)\n",
    "\n",
    "test_out=postprocess(fr_test_pred,de_test_pred,X_test,y_test)\n",
    "\n",
    "print('Spearman correlation for the test set using RidgeRegression divided into countries: {:.1f}%'.format(100 *spearman(test_out, y_test) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "304fe14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = test_out\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"Ridge\"]=[100*spearman(test_out,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5692dd",
   "metadata": {},
   "source": [
    "## SVR Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "157411c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets normalise for SVM\n",
    "\n",
    "#train set\n",
    "de_train_s=z_scale(de_train)\n",
    "y_de_train_s=z_scale(y_de_train)\n",
    "fr_train_s=z_scale(fr_train)\n",
    "y_fr_train_s=z_scale(y_fr_train)\n",
    "\n",
    "#test set\n",
    "de_test_s=z_scale(de_test)\n",
    "y_de_test_s=z_scale(y_de_test)\n",
    "fr_test_s=z_scale(fr_test)\n",
    "y_fr_test_s=z_scale(y_fr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "18a98e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with SVR split country: 22.8%\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "de_svr=SVRegression(de_train_s,y_de_train_s)\n",
    "fr_svr=SVRegression(fr_train_s,y_fr_train_s)\n",
    "\n",
    "#make predictions on train set\n",
    "de_svr_pred=de_svr.predict(de_train_s)\n",
    "fr_svr_pred=de_svr.predict(fr_train_s)\n",
    "\n",
    "train_out_svr=postprocess(fr_svr_pred,de_svr_pred,X_train,y_train)\n",
    "print('Spearman correlation for the train set with SVR split country: {:.1f}%'.format(100*spearman(train_out_svr, y_train) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "93b3a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with SVR split country: 19.8%\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the test set\n",
    "de_svr_test=de_svr.predict(de_test_s)\n",
    "fr_svr_test=fr_svr.predict(fr_test_s)\n",
    "\n",
    "test_out_svr=postprocess(fr_svr_test,de_svr_test,X_test,y_test)\n",
    "print('Spearman correlation for the test set with SVR split country: {:.1f}%'.format(100*spearman(test_out_svr, y_test) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "cdb811a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = test_out_svr\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"SVR-L\"]=[100*spearman(test_out_svr,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494c3a1",
   "metadata": {},
   "source": [
    "## SVR Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "d82efefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with SVR split country: 50.8%\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "de_svr_p=SVRegressionP(de_train_s,y_de_train_s,degree=3)\n",
    "fr_svr_p=SVRegressionP(fr_train_s,y_fr_train_s,degree=3)\n",
    "\n",
    "#make predictions on train set\n",
    "de_svr_pred_p=de_svr_p.predict(de_train_s)\n",
    "fr_svr_pred_p=de_svr_p.predict(fr_train_s)\n",
    "\n",
    "train_out_svr_p=postprocess(fr_svr_pred_p,de_svr_pred_p,X_train,y_train)\n",
    "print('Spearman correlation for the train set with SVR split country: {:.1f}%'.format(100*spearman(train_out_svr_p, y_train) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "bb5c151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with SVR split country: 5.0%\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the test set\n",
    "de_svr_test_p=de_svr_p.predict(de_test_s)\n",
    "fr_svr_test_p=fr_svr_p.predict(fr_test_s)\n",
    "\n",
    "test_out_svr_p=postprocess(fr_svr_test_p,de_svr_test_p,X_test,y_test)\n",
    "print('Spearman correlation for the test set with SVR split country: {:.1f}%'.format(100*spearman(test_out_svr_p, y_test) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "7d953128",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = test_out_svr_p\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"SVR-P\"]=[100*spearman(test_out_svr_p,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f623c6",
   "metadata": {},
   "source": [
    "## Feature Selection-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "08ff16d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE ['DE_NET_EXPORT', 'FR_WINDPOW', 'DE_RESIDUAL_LOAD']\n",
      "FR ['DE_NET_EXPORT', 'DE_HYDRO', 'FR_HYDRO', 'FR_WINDPOW', 'DE_TEMP', 'GAS_RET', 'CARBON_RET']\n"
     ]
    }
   ],
   "source": [
    "de_relevant_vars=lasso(de_train_s,y_de_train_s[\"TARGET\"])\n",
    "fr_relevant_vars=lasso(fr_train_s,y_fr_train_s[\"TARGET\"])\n",
    "\n",
    "selected_de=de_train_s[de_relevant_vars]\n",
    "selected_fr=fr_train_s[fr_relevant_vars]\n",
    "\n",
    "selected_de_test=de_test_s[de_relevant_vars]\n",
    "selected_fr_test=fr_test_s[fr_relevant_vars]\n",
    "\n",
    "print(\"DE\",de_relevant_vars)\n",
    "print(\"FR\",fr_relevant_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "53a86ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with SVR and selected: 30.4%\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "de_svr_sel=SVRegression(selected_de,y_de_train_s,C=best_C,epsilon=best_epsilon)\n",
    "fr_svr_sel=SVRegression(selected_fr,y_fr_train_s,C=best_C,epsilon=best_epsilon)\n",
    "\n",
    "#make predictions on train set\n",
    "selected_de_pred=de_svr_sel.predict(selected_de)\n",
    "selected_fr_pred=fr_svr_sel.predict(selected_fr)\n",
    "\n",
    "select_svr=postprocess(selected_fr_pred,selected_de_pred,X_train,y_train)\n",
    "print('Spearman correlation for the train set with SVR and selected: {:.1f}%'.format(100*spearman(select_svr, y_train) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "3d9aef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with SVR and selected: 26.1%\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the test set\n",
    "selected_de_test_pred=de_svr_sel.predict(selected_de_test)\n",
    "selected_fr_test_pred=fr_svr_sel.predict(selected_fr_test)\n",
    "\n",
    "select_svr_test=postprocess(selected_fr_test_pred,selected_de_test_pred,X_test,y_test)\n",
    "print('Spearman correlation for the test set with SVR and selected: {:.1f}%'.format(100*spearman(select_svr_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "b7eb15e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = select_svr_test\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"SVR_sel_L\"]=[100*spearman(select_svr_test,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e00ac6",
   "metadata": {},
   "source": [
    "## Feature Selection-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "5af39b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with SVR and selected: 30.0%\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "de_svr_sel_p=SVRegressionP(selected_de,y_de_train_s,C=best_C,epsilon=best_epsilon,degree=3)\n",
    "fr_svr_sel_p=SVRegressionP(selected_fr,y_fr_train_s,C=best_C,epsilon=best_epsilon,degree=3)\n",
    "\n",
    "#make predictions on train set\n",
    "selected_de_pred_p=de_svr_sel_p.predict(selected_de)\n",
    "selected_fr_pred_p=fr_svr_sel_p.predict(selected_fr)\n",
    "\n",
    "select_svr_p=postprocess(selected_fr_pred_p,selected_de_pred_p,X_train,y_train)\n",
    "print('Spearman correlation for the train set with SVR and selected: {:.1f}%'.format(100*spearman(select_svr_p, y_train) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "cc89a580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with SVR and selected: 16.1%\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the test set\n",
    "selected_de_test_pred_p=de_svr_sel_p.predict(selected_de_test)\n",
    "selected_fr_test_pred_p=fr_svr_sel_p.predict(selected_fr_test)\n",
    "\n",
    "select_svr_test_p=postprocess(selected_fr_test_pred_p,selected_de_test_pred_p,X_test,y_test)\n",
    "print('Spearman correlation for the test set with SVR and selected: {:.1f}%'.format(100*spearman(select_svr_test_p, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "34ceb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = select_svr_test_p\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"SVR_sel_P\"]=[100*spearman(select_svr_test_p,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae15521",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "09503983",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with GBR: 74.9%\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "gbr_de=Gboost(de_train_s,y_de_train_s)\n",
    "gbr_fr=Gboost(fr_train_s,y_fr_train_s)\n",
    "\n",
    "#make predictions on the train set\n",
    "gbr_de_pred=gbr_de.predict(de_train_s)\n",
    "gbr_fr_pred=gbr_fr.predict(fr_train_s)\n",
    "\n",
    "gbr_out=postprocess(gbr_fr_pred,gbr_de_pred,X_train,y_train)\n",
    "print('Spearman correlation for the test set with GBR: {:.1f}%'.format(100*spearman(gbr_out, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "3cfcd1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with GBR: 11.4%\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the test set\n",
    "\n",
    "gbr_de_test=gbr_de.predict(de_test_s)\n",
    "gbr_fr_test=gbr_fr.predict(fr_test_s)\n",
    "\n",
    "gbr_test_out=postprocess(gbr_fr_test,gbr_de_test,X_test,y_test)\n",
    "print('Spearman correlation for the test set with GBR: {:.1f}%'.format(100*spearman(gbr_test_out, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "23f5317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = gbr_test_out\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"Grad Boost\"]=[100*spearman(gbr_test_out,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55403053",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "92f7fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "17/17 [==============================] - 1s 4ms/step - loss: 1.1932\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1538\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1392\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1327\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1267\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1240\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1172\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1162\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1134\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1107\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1078\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1066\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1041\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1026\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1023\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0987\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0961\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0974\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0946\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0933\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0939\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0904\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0868\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0851\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0864\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.0853\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0830\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0827\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0801\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0790\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0780\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0782\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0802\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0787\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0745\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0779\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0728\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0724\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0709\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0706\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0674\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0668\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0686\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0671\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0661\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0677\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0647\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0656\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0656\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0648\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0659\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0615\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0587\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0630\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0589\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0598\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0605\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0583\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0577\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0554\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0545\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0592\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0556\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0553\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0542\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0514\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0551\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0514\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0512\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0501\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0512\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0491\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0485\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0470\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0488\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0438\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0452\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0483\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0446\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0455\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0471\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0460\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0412\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0447\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0409\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0445\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0409\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.0413\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.0396\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0384\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0410\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0383\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.0389\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0357\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0382\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0378\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0394\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0373\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0361\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0360\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0354\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0364\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0368\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0376\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0361\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0361\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0337\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0300\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0331\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0322\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0303\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0359\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0341\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0332\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0299\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0286\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0270\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0300\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0278\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0283\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0266\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0302\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0262\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0226\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0267\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0252\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0245\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0231\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0253\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0283\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0268\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0214\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0257\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0211\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0230\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0185\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0218\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0175\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0203\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0255\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0184\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0189\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0191\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0199\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0198\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0201\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0163\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0154\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0136\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0161\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0167\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0139\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0122\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0141\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0110\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0135\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0102\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0081\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0124\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0147\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0144\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0130\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0102\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0149\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0034\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0100\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0040\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0099\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0058\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0051\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0063\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0035\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0024\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0045\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9989\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0005\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0041\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0020\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0015\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0117\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9990\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0034\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0032\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9995\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9988\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9970\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0005\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0000\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9968\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9972\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9937\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9952\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9975\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9992\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9986\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9909\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9977\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9958\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9947\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23f229101d0>"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_nn_cols=[i for i,x in enumerate(de_train_ridge.coef_*100>5) if x==True]\n",
    "fr_nn_cols=[i for i,x in enumerate(fr_train_ridge.coef_*100>5) if x==True]\n",
    "\n",
    "de_nn_train=de_train_s.iloc[:,de_nn_cols]\n",
    "fr_nn_train=fr_train_s.iloc[:,fr_nn_cols]\n",
    "\n",
    "\n",
    "# Create a simple neural network model\n",
    "de_model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(de_nn_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "de_model.compile(loss=\"mse\", optimizer='sgd')\n",
    "\n",
    "# Train the model\n",
    "de_model.fit(de_nn_train, y_de_train, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "d186f870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 2ms/step - loss: 1.2581\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1268\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.1026\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0888\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0789\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0705\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0621\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0570\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0501\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0447\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0398\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0355\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0303\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0271\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0202\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0186\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0127\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0085\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0075\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0039\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9999\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9979\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9945\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9907\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9892\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9868\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9836\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9827\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9791\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9798\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9757\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9737\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9702\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9692\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9666\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9638\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9628\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9600\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9591\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9583\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9545\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9540\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9511\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9516\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9481\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9459\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9419\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9393\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9416\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9386\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9357\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9359\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9332\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9271\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9310\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9272\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9254\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9212\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9236\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9169\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9185\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9142\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9121\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9143\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9114\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9087\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9050\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9006\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9025\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9009\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8956\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8941\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8932\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8923\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8863\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8828\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8889\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8811\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8808\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8787\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8762\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8799\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8733\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8770\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8718\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8697\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8688\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8645\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8562\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8588\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8579\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8585\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8558\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.8511\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8530\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8513\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8471\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8463\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8451\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8434\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8431\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8389\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8393\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8369\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8337\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8332\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8271\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8277\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8257\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8237\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8215\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8196\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8206\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8213\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8146\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8130\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8133\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8109\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8092\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8076\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8047\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8064\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8010\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8000\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7993\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8035\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7957\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7937\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7891\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7872\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7934\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7833\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7820\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7785\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7796\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7747\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7808\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7813\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7740\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7793\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7723\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7691\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7646\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7647\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7701\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7634\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7617\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7540\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7594\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7511\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7505\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7526\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7435\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7516\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7423\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7468\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7451\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7427\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7409\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7348\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7352\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7413\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7352\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7322\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7323\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7286\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7218\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7325\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7232\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7160\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7137\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7111\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7188\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7103\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7138\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7082\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7045\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7128\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7035\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6913\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7051\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6954\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6985\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6971\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6849\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6904\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6825\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6887\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6875\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6770\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6839\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6707\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6744\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6738\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6744\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6730\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6676\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6625\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6593\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23f3afbfd90>"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple neural network model\n",
    "fr_model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(fr_nn_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "fr_model.compile(loss=\"mse\", optimizer='sgd')\n",
    "\n",
    "# Train the model\n",
    "fr_model.fit(fr_nn_train, y_fr_train, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "d151ada9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "de_nn_test=de_test_s.iloc[:,de_nn_cols]\n",
    "fr_nn_test=fr_test_s.iloc[:,fr_nn_cols]\n",
    "\n",
    "de_nn_pred=de_model.predict(de_nn_test)\n",
    "fr_nn_pred=fr_model.predict(fr_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "e9306e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with NN: 10.9%\n"
     ]
    }
   ],
   "source": [
    "nn_test_out=postprocess(fr_nn_pred,de_nn_pred,X_test,y_test)\n",
    "nn_test_out=nn_test_out.reshape(nn_test_out.shape[0],-1)\n",
    "print('Spearman correlation for the test set with NN: {:.1f}%'.format(100*spearman(nn_test_out, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "37c1ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = nn_test_out\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"NN\"]=[100*spearman(nn_test_out,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe794e",
   "metadata": {},
   "source": [
    "## Poly with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "cb56fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with poly features: 27.5%\n"
     ]
    }
   ],
   "source": [
    "lr_cv=LinearRegression()\n",
    "scores_de=cross_val_score(lr_cv,de_nn_train,y_de_train,scoring=\"r2\",cv=5)\n",
    "scores_fr=cross_val_score(lr_cv,fr_nn_train,y_fr_train,scoring=\"r2\",cv=5)\n",
    "\n",
    "poly_de=PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_fr=PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "poly_feat_de=poly_de.fit_transform(de_nn_train)\n",
    "poly_feat_fr=poly_fr.fit_transform(fr_nn_train)\n",
    "poly_de_out=poly_de.transform(de_nn_train)\n",
    "poly_fr_out=poly_fr.transform(fr_nn_train)\n",
    "poly_de_test_out=poly_de.transform(de_nn_test)\n",
    "poly_fr_test_out=poly_fr.transform(fr_nn_test)\n",
    "\n",
    "lr_poly_de=LinearRegression()\n",
    "lr_poly_fr=LinearRegression()\n",
    "\n",
    "#fit the model\n",
    "lr_poly_de.fit(poly_feat_de,y_de_train)\n",
    "lr_poly_fr.fit(poly_feat_fr,y_fr_train)\n",
    "\n",
    "#predict on train set\n",
    "lr_poly_de_pred=lr_poly_de.predict(poly_de_out)\n",
    "lr_poly_fr_pred=lr_poly_fr.predict(poly_fr_out)\n",
    "\n",
    "\n",
    "poly_train_out=postprocess(lr_poly_fr_pred,lr_poly_de_pred,X_train,y_train)\n",
    "print('Spearman correlation for the train set with poly features: {:.1f}%'.format(100*spearman(poly_train_out, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "59609bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with poly features: 14.2%\n"
     ]
    }
   ],
   "source": [
    "#predict on test set\n",
    "lr_poly_de_test=lr_poly_de.predict(poly_de_test_out)\n",
    "lr_poly_fr_test=lr_poly_fr.predict(poly_fr_test_out)\n",
    "\n",
    "poly_test_out=postprocess(lr_poly_fr_test,lr_poly_de_test,X_test,y_test)\n",
    "print('Spearman correlation for the test set with poly features: {:.1f}%'.format(100*spearman(poly_test_out, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "e017ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = poly_test_out\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"Poly\"]=[100*spearman(poly_test_out,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d892c2f",
   "metadata": {},
   "source": [
    "## Removing low correlation features from train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "ad41e3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DE_CONSUMPTION</th>\n",
       "      <th>FR_DE_EXCHANGE</th>\n",
       "      <th>DE_NET_EXPORT</th>\n",
       "      <th>DE_GAS</th>\n",
       "      <th>DE_COAL</th>\n",
       "      <th>DE_HYDRO</th>\n",
       "      <th>DE_WINDPOW</th>\n",
       "      <th>FR_WINDPOW</th>\n",
       "      <th>DE_LIGNITE</th>\n",
       "      <th>DE_RESIDUAL_LOAD</th>\n",
       "      <th>DE_WIND</th>\n",
       "      <th>FR_WIND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-0.990367</td>\n",
       "      <td>0.198628</td>\n",
       "      <td>-0.112689</td>\n",
       "      <td>0.746947</td>\n",
       "      <td>-1.231858</td>\n",
       "      <td>0.955491</td>\n",
       "      <td>0.354309</td>\n",
       "      <td>-0.373501</td>\n",
       "      <td>-0.994481</td>\n",
       "      <td>-1.106939</td>\n",
       "      <td>-0.397712</td>\n",
       "      <td>-0.611540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>-1.257929</td>\n",
       "      <td>-0.904792</td>\n",
       "      <td>-1.128043</td>\n",
       "      <td>0.336427</td>\n",
       "      <td>-0.248216</td>\n",
       "      <td>-0.093396</td>\n",
       "      <td>-1.012889</td>\n",
       "      <td>-0.485072</td>\n",
       "      <td>0.431948</td>\n",
       "      <td>-0.036186</td>\n",
       "      <td>-0.145876</td>\n",
       "      <td>-0.001253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1.247370</td>\n",
       "      <td>-0.238350</td>\n",
       "      <td>1.957018</td>\n",
       "      <td>-0.828563</td>\n",
       "      <td>0.535648</td>\n",
       "      <td>-0.724273</td>\n",
       "      <td>1.229340</td>\n",
       "      <td>2.253539</td>\n",
       "      <td>1.534373</td>\n",
       "      <td>0.052753</td>\n",
       "      <td>-0.433753</td>\n",
       "      <td>0.259285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>0.757594</td>\n",
       "      <td>0.384985</td>\n",
       "      <td>0.503730</td>\n",
       "      <td>0.583682</td>\n",
       "      <td>0.508438</td>\n",
       "      <td>-0.934737</td>\n",
       "      <td>0.260839</td>\n",
       "      <td>-0.081582</td>\n",
       "      <td>1.454654</td>\n",
       "      <td>0.746415</td>\n",
       "      <td>-0.714662</td>\n",
       "      <td>-1.082914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>-1.064563</td>\n",
       "      <td>0.322065</td>\n",
       "      <td>-0.809799</td>\n",
       "      <td>0.990596</td>\n",
       "      <td>-1.449589</td>\n",
       "      <td>0.575730</td>\n",
       "      <td>-0.669549</td>\n",
       "      <td>-0.353574</td>\n",
       "      <td>-0.741543</td>\n",
       "      <td>-0.414415</td>\n",
       "      <td>-0.624999</td>\n",
       "      <td>-0.571376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>0.014438</td>\n",
       "      <td>1.130875</td>\n",
       "      <td>-0.992926</td>\n",
       "      <td>-0.564654</td>\n",
       "      <td>-0.634773</td>\n",
       "      <td>1.935940</td>\n",
       "      <td>0.159720</td>\n",
       "      <td>-0.640959</td>\n",
       "      <td>-0.894973</td>\n",
       "      <td>-0.136310</td>\n",
       "      <td>-0.321932</td>\n",
       "      <td>-0.889216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>-1.100194</td>\n",
       "      <td>-0.154824</td>\n",
       "      <td>-0.787350</td>\n",
       "      <td>1.016932</td>\n",
       "      <td>-1.560615</td>\n",
       "      <td>0.063379</td>\n",
       "      <td>-0.764226</td>\n",
       "      <td>-0.842038</td>\n",
       "      <td>-1.019175</td>\n",
       "      <td>-0.438511</td>\n",
       "      <td>-1.015912</td>\n",
       "      <td>-1.311008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>-0.261258</td>\n",
       "      <td>-1.716863</td>\n",
       "      <td>1.131331</td>\n",
       "      <td>-1.406768</td>\n",
       "      <td>0.542796</td>\n",
       "      <td>0.519813</td>\n",
       "      <td>0.601356</td>\n",
       "      <td>-0.563063</td>\n",
       "      <td>0.530200</td>\n",
       "      <td>-0.871749</td>\n",
       "      <td>0.840039</td>\n",
       "      <td>0.276001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>0.722508</td>\n",
       "      <td>-0.083001</td>\n",
       "      <td>1.433830</td>\n",
       "      <td>-1.298742</td>\n",
       "      <td>-0.428195</td>\n",
       "      <td>-0.013122</td>\n",
       "      <td>1.645208</td>\n",
       "      <td>2.137466</td>\n",
       "      <td>0.455033</td>\n",
       "      <td>-0.850250</td>\n",
       "      <td>-0.358423</td>\n",
       "      <td>0.056160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>0.159080</td>\n",
       "      <td>0.490527</td>\n",
       "      <td>-0.864386</td>\n",
       "      <td>0.071724</td>\n",
       "      <td>-0.628976</td>\n",
       "      <td>-0.445541</td>\n",
       "      <td>-0.559167</td>\n",
       "      <td>-0.838287</td>\n",
       "      <td>-0.837543</td>\n",
       "      <td>0.184944</td>\n",
       "      <td>-0.321932</td>\n",
       "      <td>-0.221974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DE_CONSUMPTION  FR_DE_EXCHANGE  DE_NET_EXPORT    DE_GAS   DE_COAL  \\\n",
       "173        -0.990367        0.198628      -0.112689  0.746947 -1.231858   \n",
       "448        -1.257929       -0.904792      -1.128043  0.336427 -0.248216   \n",
       "1109        1.247370       -0.238350       1.957018 -0.828563  0.535648   \n",
       "1311        0.757594        0.384985       0.503730  0.583682  0.508438   \n",
       "643        -1.064563        0.322065      -0.809799  0.990596 -1.449589   \n",
       "...              ...             ...            ...       ...       ...   \n",
       "1484        0.014438        1.130875      -0.992926 -0.564654 -0.634773   \n",
       "366        -1.100194       -0.154824      -0.787350  1.016932 -1.560615   \n",
       "523        -0.261258       -1.716863       1.131331 -1.406768  0.542796   \n",
       "1062        0.722508       -0.083001       1.433830 -1.298742 -0.428195   \n",
       "1128        0.159080        0.490527      -0.864386  0.071724 -0.628976   \n",
       "\n",
       "      DE_HYDRO  DE_WINDPOW  FR_WINDPOW  DE_LIGNITE  DE_RESIDUAL_LOAD  \\\n",
       "173   0.955491    0.354309   -0.373501   -0.994481         -1.106939   \n",
       "448  -0.093396   -1.012889   -0.485072    0.431948         -0.036186   \n",
       "1109 -0.724273    1.229340    2.253539    1.534373          0.052753   \n",
       "1311 -0.934737    0.260839   -0.081582    1.454654          0.746415   \n",
       "643   0.575730   -0.669549   -0.353574   -0.741543         -0.414415   \n",
       "...        ...         ...         ...         ...               ...   \n",
       "1484  1.935940    0.159720   -0.640959   -0.894973         -0.136310   \n",
       "366   0.063379   -0.764226   -0.842038   -1.019175         -0.438511   \n",
       "523   0.519813    0.601356   -0.563063    0.530200         -0.871749   \n",
       "1062 -0.013122    1.645208    2.137466    0.455033         -0.850250   \n",
       "1128 -0.445541   -0.559167   -0.838287   -0.837543          0.184944   \n",
       "\n",
       "       DE_WIND   FR_WIND  \n",
       "173  -0.397712 -0.611540  \n",
       "448  -0.145876 -0.001253  \n",
       "1109 -0.433753  0.259285  \n",
       "1311 -0.714662 -1.082914  \n",
       "643  -0.624999 -0.571376  \n",
       "...        ...       ...  \n",
       "1484 -0.321932 -0.889216  \n",
       "366  -1.015912 -1.311008  \n",
       "523   0.840039  0.276001  \n",
       "1062 -0.358423  0.056160  \n",
       "1128 -0.321932 -0.221974  \n",
       "\n",
       "[118 rows x 12 columns]"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold=0.06\n",
    "\n",
    "corr_de=de_train_s.corrwith(y_de_train)\n",
    "de_train_c=de_train_s.loc[:,abs(corr_de)>threshold]\n",
    "de_test_c=de_test_s.loc[:,abs(corr_de)>threshold]\n",
    "corr_fr=fr_train_s.corrwith(y_fr_train)\n",
    "fr_train_c=fr_train_s.loc[:,abs(corr_fr)>threshold]\n",
    "fr_test_c=fr_test_s.loc[:,abs(corr_fr)>threshold]\n",
    "\n",
    "de_test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "f67b44a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with SVR split country: 32.7%\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "de_svr_c=SVRegression(de_train_c,y_de_train_s,C=best_C,epsilon=best_epsilon)\n",
    "fr_svr_c=SVRegression(fr_train_c,y_fr_train_s,C=best_C,epsilon=best_epsilon)\n",
    "\n",
    "#make predictions on train set\n",
    "de_svr_pred_c=de_svr_c.predict(de_train_c)\n",
    "fr_svr_pred_c=fr_svr_c.predict(fr_train_c)\n",
    "\n",
    "train_out_svr_c=postprocess(fr_svr_pred_c,de_svr_pred_c,X_train,y_train)\n",
    "print('Spearman correlation for the train set with SVR split country: {:.1f}%'.format(100*spearman(train_out_svr_c, y_train) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "aab1c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with SVR split country: 27.3%\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the test set\n",
    "de_svr_test_c=de_svr_c.predict(de_test_c)\n",
    "fr_svr_test_c=fr_svr_c.predict(fr_test_c)\n",
    "\n",
    "test_out_svr_c=postprocess(fr_svr_test_c,de_svr_test_c,X_test,y_test)\n",
    "print('Spearman correlation for the test set with SVR split country: {:.1f}%'.format(100*spearman(test_out_svr_c, y_test) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "68659589",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = test_out_svr_c\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"SVR-C\"]=[100*spearman(test_out_svr_c,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd685b",
   "metadata": {},
   "source": [
    "## Manual Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "032adc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_cols=[\"FR_DE_EXCHANGE\"]\n",
    "fr_cols=[]\n",
    "for i in list(de_train_s.columns):\n",
    "    if i[0:2]==\"DE\":\n",
    "        de_cols.append(i)\n",
    "    elif i[0:2]==\"FR\":\n",
    "        fr_cols.append(i)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "de_train_m=de_train_s[de_cols]\n",
    "fr_train_m=fr_train_s[de_cols]\n",
    "de_test_m=de_test_s[de_cols]\n",
    "fr_test_m=fr_test_s[de_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "2e4e2830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with SVR split country: 29.8%\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "de_svr_m=SVRegression(de_train_m,y_de_train_s,C=best_C,epsilon=best_epsilon)\n",
    "fr_svr_m=SVRegression(fr_train_m,y_fr_train_s,C=best_C,epsilon=best_epsilon)\n",
    "\n",
    "#make predictions on train set\n",
    "de_svr_pred_m=de_svr_m.predict(de_train_m)\n",
    "fr_svr_pred_m=fr_svr_m.predict(fr_train_m)\n",
    "\n",
    "train_out_svr_m=postprocess(fr_svr_pred_m,de_svr_pred_m,X_train,y_train)\n",
    "print('Spearman correlation for the train set with SVR split country: {:.1f}%'.format(100*spearman(train_out_svr_m, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "b46edc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with SVR split country: 23.1%\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the test set\n",
    "de_svr_test_m=de_svr_m.predict(de_test_m)\n",
    "fr_svr_test_m=fr_svr_m.predict(fr_test_m)\n",
    "\n",
    "test_out_svr_m=postprocess(fr_svr_test_m,de_svr_test_m,X_test,y_test)\n",
    "print('Spearman correlation for the test set with SVR split country: {:.1f}%'.format(100*spearman(test_out_svr_m, y_test) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "3ddb38b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = test_out_svr_m\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"SVR-M\"]=[100*spearman(test_out_svr_m,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1205b6e6",
   "metadata": {},
   "source": [
    "## Neutral Network with selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "b34ae552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "17/17 [==============================] - 1s 2ms/step - loss: 1.2189\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1406\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.1003\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0703\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0441\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0348\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0137\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0038\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9916\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.9845\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9726\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9755\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9557\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9535\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9494\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9491\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9394\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.9305\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.9169\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9317\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9165\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.9087\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.9031\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8940\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8944\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8923\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8906\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8833\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8805\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8698\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8681\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8551\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8607\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.8577\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8475\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8457\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8428\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.8326\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8280\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8259\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8207\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8182\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8121\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.8058\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7979\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7979\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7907\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7846\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7805\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7793\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7723\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7799\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7696\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7670\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7612\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7504\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7555\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7399\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7459\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7402\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7384\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7483\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7254\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7184\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7175\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7154\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7147\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7104\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6983\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6941\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6903\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6897\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6835\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6778\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6831\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6824\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6663\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6618\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6650\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6650\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6535\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6533\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6645\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6510\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6489\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6364\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6370\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6242\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6133\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6360\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6222\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6134\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6162\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6018\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6027\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6241\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5985\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5928\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5766\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5919\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5748\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5850\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5668\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5663\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5662\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5588\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5541\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5458\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5437\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5463\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5515\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5519\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5412\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5324\n",
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5380\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5186\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5170\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5121\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5170\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5147\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5154\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5014\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5038\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4954\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4979\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4857\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4961\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4782\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4998\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4878\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4749\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4736\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4686\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4899\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4589\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4550\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4483\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4500\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4408\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4719\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4541\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4362\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4313\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4262\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4292\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4422\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4142\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4186\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4133\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4163\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4756\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4076\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4049\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4096\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4003\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4016\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3815\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4002\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3993\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3833\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3832\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3873\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3736\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 949us/step - loss: 0.3653\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3830\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3777\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3724\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3634\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3661\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3540\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3853\n",
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3621\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3338\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3514\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3384\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4061\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3505\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3395\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3505\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3409\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3323\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3499\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3461\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3329\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3492\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2988\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3255\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3200\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3200\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3283\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3125\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3161\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3253\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3073\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2982\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2977\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2973\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2827\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2886\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23f361cbf90>"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_nn_train=de_train_s.loc[:,de_cols]\n",
    "fr_nn_train=fr_train_s.loc[:,fr_cols]\n",
    "\n",
    "\n",
    "# Create a simple neural network model\n",
    "de_model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(de_nn_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "de_model.compile(loss=\"mse\", optimizer='sgd')\n",
    "\n",
    "# Train the model\n",
    "de_model.fit(de_nn_train, y_de_train, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "409e892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 2ms/step - loss: 1.1385\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0840\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0658\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 1.0526\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 1.0435\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 1.0323\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0256\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0228\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0112\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0112\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1.0038\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9984\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9925\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9850\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9860\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9793\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9725\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9734\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9667\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9580\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.9583\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9551\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9474\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9462\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9426\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9376\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.9376\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.9313\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9293\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9201\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9182\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9122\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9056\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.9050\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.9051\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8988\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8995\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8906\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8904\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8871\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8816\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8738\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8763\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8712\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8661\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8628\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8617\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8589\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8551\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8526\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8409\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8429\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8440\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8300\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8293\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8167\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8231\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8284\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8179\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8062\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8103\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8094\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8024\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8014\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7920\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7960\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7962\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7860\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7904\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7807\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7764\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7669\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7650\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7649\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7622\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7635\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7561\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7419\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7507\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7448\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7383\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7435\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7281\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7235\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7262\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7301\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7168\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7250\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7208\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7136\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7091\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6993\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6974\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6998\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6881\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6931\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6924\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6795\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6821\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6774\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6677\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6795\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6657\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6573\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6706\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6543\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6546\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6578\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6541\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6343\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6447\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6394\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6431\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6449\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6428\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6497\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6139\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6158\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6142\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6196\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6056\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6109\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5981\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5934\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6077\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5987\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5912\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5827\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5914\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5734\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5771\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5588\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5734\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5628\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5782\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5710\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5466\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5562\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5532\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5450\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5464\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5415\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5509\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5385\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5234\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5442\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5406\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5226\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5478\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5127\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4997\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5114\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5054\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5049\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4963\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5239\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4950\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4902\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4912\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4813\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4850\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.5055\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4811\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4614\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4850\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4752\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4804\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4677\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4641\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4715\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4485\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4423\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4331\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4536\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4580\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4522\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4690\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4695\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4647\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4244\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4576\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4549\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4525\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4252\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4132\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4430\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4294\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4139\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4377\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4122\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4104\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4131\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3897\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.4020\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4252\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3986\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4066\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4199\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4153\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23f3794bf90>"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple neural network model\n",
    "fr_model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(fr_nn_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Single output for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "fr_model.compile(loss=\"mse\", optimizer='sgd')\n",
    "\n",
    "# Train the model\n",
    "fr_model.fit(fr_nn_train, y_fr_train, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "4fabe669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "de_nn_test=de_test_s.loc[:,de_cols]\n",
    "fr_nn_test=fr_test_s.loc[:,fr_cols]\n",
    "\n",
    "de_nn_pred=de_model.predict(de_nn_test)\n",
    "fr_nn_pred=fr_model.predict(fr_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "355c2aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with NN: 14.2%\n"
     ]
    }
   ],
   "source": [
    "nn_test_out=postprocess(fr_nn_pred,de_nn_pred,X_test,y_test)\n",
    "nn_test_out=nn_test_out.reshape(nn_test_out.shape[0],-1)\n",
    "print('Spearman correlation for the test set with NN: {:.1f}%'.format(100*spearman(nn_test_out, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "653763c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = nn_test_out\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"NN-m\"]=[100*spearman(nn_test_out,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f4e49",
   "metadata": {},
   "source": [
    "## KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "9fde7fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with KNN: 38.3%\n"
     ]
    }
   ],
   "source": [
    "knn_de = KNeighborsRegressor(n_neighbors=11)\n",
    "knn_fr = KNeighborsRegressor(n_neighbors=11)\n",
    "\n",
    "#fit the model\n",
    "knn_de.fit(de_train_c,y_de_train_s)\n",
    "knn_fr.fit(fr_train_c,y_fr_train_s)\n",
    "\n",
    "#make predictions on train set\n",
    "knn_de_pred=knn_de.predict(de_train_c)\n",
    "knn_fr_pred=knn_fr.predict(fr_train_c)\n",
    "\n",
    "knn_train_out=postprocess(knn_fr_pred,knn_de_pred,X_train,y_train)\n",
    "knn_train_out=knn_train_out.reshape(knn_train_out.shape[0],-1)\n",
    "print('Spearman correlation for the train set with KNN: {:.1f}%'.format(100*spearman(knn_train_out, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "d5d5baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the test set with KNN: 15.6%\n"
     ]
    }
   ],
   "source": [
    "knn_de_test=knn_de.predict(de_test_c)\n",
    "knn_fr_test=knn_fr.predict(fr_test_c)\n",
    "knn_test_out=postprocess(knn_fr_test,knn_de_test,X_test,y_test)\n",
    "knn_test_out=knn_test_out.reshape(knn_test_out.shape[0],-1)\n",
    "print('Spearman correlation for the test set with KNN: {:.1f}%'.format(100*spearman(knn_test_out, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "813dee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_clean = X_test.drop(['COUNTRY'], axis=1).fillna(0)\n",
    "\n",
    "Y_test_submission = X_test[['ID']].copy()\n",
    "Y_test_submission['TARGET'] = knn_test_out\n",
    "\n",
    "mse_test=mean_squared_error(y_test,Y_test_submission[\"TARGET\"])\n",
    "mse_test\n",
    "\n",
    "results_matrix[\"KNN\"]=[100*spearman(knn_test_out,y_test),mse_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39fa77",
   "metadata": {},
   "source": [
    "## Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "02b67b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with Bayesian: 31.3%\n"
     ]
    }
   ],
   "source": [
    "br_de = BayesianRidge(max_iter=300,tol=0.001,alpha_1=1e-6,lambda_1=1e-6)\n",
    "br_fr = BayesianRidge(max_iter=300,tol=0.001,alpha_1=1e-6,lambda_1=1e-6)\n",
    "\n",
    "#fit the model\n",
    "br_de.fit(de_train_c,y_de_train_s[\"TARGET\"])\n",
    "br_fr.fit(fr_train_c,y_fr_train_s[\"TARGET\"])\n",
    "\n",
    "#predict on train set\n",
    "br_de_pred=br_de.predict(de_train_c)\n",
    "br_fr_pred=br_fr.predict(fr_train_c)\n",
    "\n",
    "br_train_out=postprocess(br_fr_pred,br_de_pred,X_train,y_train)\n",
    "br_train_out=br_train_out.reshape(br_train_out.shape[0],-1)\n",
    "print('Spearman correlation for the train set with Bayesian: {:.1f}%'.format(100*spearman(br_train_out, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "0c7076dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for the train set with Bayesian: 25.3%\n"
     ]
    }
   ],
   "source": [
    "#predict on test set\n",
    "br_de_test=br_de.predict(de_test_c)\n",
    "br_fr_test=br_fr.predict(fr_test_c)\n",
    "\n",
    "br_test_out=postprocess(br_fr_test,br_de_test,X_test,y_test)\n",
    "br_test_out=br_test_out.reshape(br_test_out.shape[0],-1)\n",
    "print('Spearman correlation for the train set with Bayesian: {:.1f}%'.format(100*spearman(br_test_out, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "8f845a4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>SVR-L</th>\n",
       "      <th>SVR-P</th>\n",
       "      <th>SVR_sel_L</th>\n",
       "      <th>SVR_sel_P</th>\n",
       "      <th>Grad Boost</th>\n",
       "      <th>NN</th>\n",
       "      <th>Poly</th>\n",
       "      <th>SVR-C</th>\n",
       "      <th>SVR-M</th>\n",
       "      <th>SVR-MM</th>\n",
       "      <th>NN-m</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>21.56</td>\n",
       "      <td>25.11</td>\n",
       "      <td>19.84</td>\n",
       "      <td>5.00</td>\n",
       "      <td>26.15</td>\n",
       "      <td>16.14</td>\n",
       "      <td>11.42</td>\n",
       "      <td>10.94</td>\n",
       "      <td>14.16</td>\n",
       "      <td>27.29</td>\n",
       "      <td>23.12</td>\n",
       "      <td>20.5</td>\n",
       "      <td>14.23</td>\n",
       "      <td>15.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Benchmark  Ridge  SVR-L  SVR-P  SVR_sel_L  SVR_sel_P  Grad Boost     NN  \\\n",
       "SR       21.56  25.11  19.84   5.00      26.15      16.14       11.42  10.94   \n",
       "MSE       0.81   0.79   0.80   1.49       0.80       0.91        0.93   0.89   \n",
       "\n",
       "      Poly  SVR-C  SVR-M  SVR-MM   NN-m    KNN  \n",
       "SR   14.16  27.29  23.12    20.5  14.23  15.58  \n",
       "MSE   0.80   0.80   0.81     0.8   1.14   0.85  "
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_matrix=results_matrix.round(2)\n",
    "results_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
